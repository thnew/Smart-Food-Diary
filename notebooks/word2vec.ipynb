{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from spellchecker import SpellChecker\n",
    "from nltk.metrics.distance import edit_distance\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"myfitnesspal_1k_sample_14.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Name', 'Meal', 'Brand', 'Calories', 'Carbs', 'Fat', 'Protein',\n",
       "       'Sodium', 'Amount', 'Units'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(subset='Meal', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_foods = df['Meal'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10310"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_foods)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10310, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enrich dataset with more foods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "food = pd.read_csv(\"data/food_update_log_entry.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df = food['description'].str.lower().str.split(r'[,|)|(|-]', expand=True, n=1)\n",
    "tmp_df = tmp_df[0].str.strip()\n",
    "tmp_list = tmp_df.drop_duplicates().dropna().to_list()\n",
    "len(tmp_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_food = pd.read_csv(\"foodb_2020_04_07_csv/Food.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_food.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine and preprocess the 2 lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10583"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enriched_food_list = tmp_list + list_foods\n",
    "len(enriched_food_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10583"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens = []\n",
    "for i, sentence in enumerate(enriched_food_list):\n",
    "    try:\n",
    "        word_tokens.append(word_tokenize(sentence))\n",
    "    except TypeError:\n",
    "        print(f\"Error at {i}: {sentence}\")\n",
    "len(word_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10583"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "total_list_no_stopwords = []\n",
    "for list in word_tokens:\n",
    "    stopwords_list = [w for w in list if not w in stop_words]\n",
    "    total_list_no_stopwords.append(stopwords_list)\n",
    "len(total_list_no_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10583"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_processsed = []\n",
    "for list in total_list_no_stopwords:\n",
    "    noun_lemmatized = [WordNetLemmatizer().lemmatize(word, pos = \"n\") for word in list]\n",
    "    dataset_processsed.append(noun_lemmatized)\n",
    "len(dataset_processsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10310"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original = dataset_processsed[273:]\n",
    "len(original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the processed meals into the dataset\n",
    "df['processed'] = original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed'] = df['processed'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Meal</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Calories</th>\n",
       "      <th>Carbs</th>\n",
       "      <th>Fat</th>\n",
       "      <th>Protein</th>\n",
       "      <th>Sodium</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Units</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my - mcdonalds espresso pronto  flat white</td>\n",
       "      <td>mcdonalds espresso pronto  flat white</td>\n",
       "      <td>my</td>\n",
       "      <td>412</td>\n",
       "      <td>29</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>258</td>\n",
       "      <td>2.0</td>\n",
       "      <td>tall</td>\n",
       "      <td>mcdonalds espresso pronto flat white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quest bar - banana nut muffin natural protein bar</td>\n",
       "      <td>banana nut muffin natural protein bar</td>\n",
       "      <td>quest bar</td>\n",
       "      <td>170</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>260</td>\n",
       "      <td>60.0</td>\n",
       "      <td>g</td>\n",
       "      <td>banana nut muffin natural protein bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uncle tobys australia - vita brits</td>\n",
       "      <td>vita brits</td>\n",
       "      <td>uncle tobys australia</td>\n",
       "      <td>176</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>195</td>\n",
       "      <td>3.0</td>\n",
       "      <td>biscuits</td>\n",
       "      <td>vita brit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pauls - smarter white milk</td>\n",
       "      <td>smarter white milk</td>\n",
       "      <td>pauls</td>\n",
       "      <td>342</td>\n",
       "      <td>34</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>402</td>\n",
       "      <td>600.0</td>\n",
       "      <td>ml</td>\n",
       "      <td>smarter white milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>quest bar - cookies and cream</td>\n",
       "      <td>cookies and cream</td>\n",
       "      <td>quest bar</td>\n",
       "      <td>180</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bar</td>\n",
       "      <td>cooky cream</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name  \\\n",
       "0         my - mcdonalds espresso pronto  flat white   \n",
       "1  quest bar - banana nut muffin natural protein bar   \n",
       "2                 uncle tobys australia - vita brits   \n",
       "3                         pauls - smarter white milk   \n",
       "4                      quest bar - cookies and cream   \n",
       "\n",
       "                                     Meal                   Brand  Calories  \\\n",
       "0   mcdonalds espresso pronto  flat white                     my        412   \n",
       "1   banana nut muffin natural protein bar              quest bar        170   \n",
       "2                              vita brits  uncle tobys australia        176   \n",
       "3                      smarter white milk                  pauls        342   \n",
       "4                       cookies and cream              quest bar        180   \n",
       "\n",
       "   Carbs  Fat  Protein  Sodium  Amount     Units  \\\n",
       "0     29   24       21     258     2.0      tall   \n",
       "1     25    5       20     260    60.0         g   \n",
       "2     33    1        5     195     3.0  biscuits   \n",
       "3     34   12       24     402   600.0        ml   \n",
       "4     22    7       21     310     1.0       bar   \n",
       "\n",
       "                               processed  \n",
       "0   mcdonalds espresso pronto flat white  \n",
       "1  banana nut muffin natural protein bar  \n",
       "2                              vita brit  \n",
       "3                     smarter white milk  \n",
       "4                            cooky cream  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply the Word2Vec to embed the tokenized dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create word embeddings\n",
    "        Create a word to 100dim-vector df or dict\n",
    "#### 2. Sum words for each sentntence (sentence to vector df/dict)\n",
    "#### 3. Create input embedding\n",
    "#### 4. Compare input dict to sentence dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create word embeddings\n",
    "word2vec = Word2Vec(dataset_processsed, min_count=1, window = 5)\n",
    "vectors = word2vec.wv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10583"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_processsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectors.vectors[1].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3360"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word2vec.corpus_total_words\n",
    "len(vectors.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wv['melon']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6616"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentence_to_vect_dataset.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_to_vect_dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(sentence_to_vect_datatset['mcdonalds espresso pronto flat white'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('salad', 0.999779462814331),\n",
       " ('-', 0.999150812625885),\n",
       " ('mix', 0.9991172552108765),\n",
       " ('oz', 0.9990977048873901),\n",
       " ('latte', 0.999068558216095),\n",
       " ('beef', 0.9990552663803101),\n",
       " (\"''\", 0.999039888381958),\n",
       " ('fruit', 0.9990172386169434),\n",
       " ('water', 0.9990145564079285),\n",
       " ('cheese', 0.9989919066429138)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wv.similar_by_word(wv['melon'] + wv['salad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = vectors.similar_by_word('muffin')\n",
    "type(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Word2Vec model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14181457, 17898000)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec.train(dataset_processsed, total_examples = len(dataset_processsed), epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a word to vector dict\n",
    "word_to_vect_dataset = {}\n",
    "for word in word2vec.wv.index_to_key:\n",
    "    vector = word2vec.wv[word]\n",
    "    word_to_vect_dataset[word] = vector\n",
    "# word_to_vect_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sentence to vector dict\n",
    "sentence_to_vect_dataset = {}\n",
    "for list_ in original:\n",
    "    total = np.zeros(100)\n",
    "    sentence = ''\n",
    "    for word in list_:\n",
    "        if word in word_to_vect_dataset.keys():\n",
    "            total += word_to_vect_dataset[word]\n",
    "            sentence += word + \" \"\n",
    "    sentence_to_vect_dataset[sentence.strip()] = total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess and embed the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = 'fruit salad'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fruit', 'salad']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens_input = word_tokenize(input_sentence)\n",
    "word_tokens_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fruit', 'salad']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords_input= [w for w in word_tokens_input if not w in stop_words]\n",
    "stopwords_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fruit', 'salad']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "noun_lemmatized = [WordNetLemmatizer().lemmatize(word, pos = \"n\") for word in stopwords_input]\n",
    "noun_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fruit', 'salad']"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find an embeded vector for the input inside our dataset. It should output the closest sum vector macthed to words existing in datatset.\n",
    "# If it doesn't exist, it will spell check and look again\n",
    "\n",
    "word_tokens_input_corr = []\n",
    "spell = SpellChecker(distance=2)\n",
    "misspelled = spell.unknown(noun_lemmatized)\n",
    "total_vectors_found = np.zeros(100)\n",
    "for word in noun_lemmatized:\n",
    "    if word in word_to_vect_dataset.keys():\n",
    "        total_vectors_found += word_to_vect_dataset[word]\n",
    "        word_tokens_input_corr.append(word)\n",
    "    else:\n",
    "        try:\n",
    "            if word in misspelled:\n",
    "                corr_word = spell.correction(word)\n",
    "                word_tokens_input_corr.append(corr_word)\n",
    "\n",
    "                total_vectors_found += word_to_vect_dataset[corr_word]\n",
    "            else:\n",
    "                total_vectors_found += np.zeros(100)\n",
    "                word_tokens_input_corr.append(word)\n",
    "        except:\n",
    "            total_vectors_found += np.zeros(100)\n",
    "# total_vectors_found\n",
    "word_tokens_input_corr = [WordNetLemmatizer().lemmatize(word, pos = \"n\") for word in word_tokens_input_corr]\n",
    "word_tokens_input_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Look for similarities in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarities = {}\n",
    "# input_vector = list(word_to_vect_input.values())[0][0]\n",
    "for sentence, vector in sentence_to_vect_dataset.items():\n",
    "    similarity_score = cosine_similarity([total_vectors_found], [vector])\n",
    "    similarities[sentence] = similarity_score\n",
    "top_n = 10\n",
    "sorted_similarities = sorted(similarities.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "# Number of most similar sentences to print\n",
    "# for sentence, similarity_score in sorted_similarities[:top_n]:\n",
    "# print(f\"Sentence: {sentence}, Similarity Score: {similarity_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(similarities.values())[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fruit salad'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_key = max(similarities, key=lambda k: similarities[k][0][0])\n",
    "max_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarities['protein bar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fruit salad'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_similarities[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Meal</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Calories</th>\n",
       "      <th>Carbs</th>\n",
       "      <th>Fat</th>\n",
       "      <th>Protein</th>\n",
       "      <th>Sodium</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Units</th>\n",
       "      <th>processed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my - mcdonalds espresso pronto  flat white</td>\n",
       "      <td>mcdonalds espresso pronto  flat white</td>\n",
       "      <td>my</td>\n",
       "      <td>412</td>\n",
       "      <td>29</td>\n",
       "      <td>24</td>\n",
       "      <td>21</td>\n",
       "      <td>258</td>\n",
       "      <td>2.0</td>\n",
       "      <td>tall</td>\n",
       "      <td>mcdonalds espresso pronto flat white</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>quest bar - banana nut muffin natural protein bar</td>\n",
       "      <td>banana nut muffin natural protein bar</td>\n",
       "      <td>quest bar</td>\n",
       "      <td>170</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>260</td>\n",
       "      <td>60.0</td>\n",
       "      <td>g</td>\n",
       "      <td>banana nut muffin natural protein bar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>uncle tobys australia - vita brits</td>\n",
       "      <td>vita brits</td>\n",
       "      <td>uncle tobys australia</td>\n",
       "      <td>176</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>195</td>\n",
       "      <td>3.0</td>\n",
       "      <td>biscuits</td>\n",
       "      <td>vita brit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pauls - smarter white milk</td>\n",
       "      <td>smarter white milk</td>\n",
       "      <td>pauls</td>\n",
       "      <td>342</td>\n",
       "      <td>34</td>\n",
       "      <td>12</td>\n",
       "      <td>24</td>\n",
       "      <td>402</td>\n",
       "      <td>600.0</td>\n",
       "      <td>ml</td>\n",
       "      <td>smarter white milk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>quest bar - cookies and cream</td>\n",
       "      <td>cookies and cream</td>\n",
       "      <td>quest bar</td>\n",
       "      <td>180</td>\n",
       "      <td>22</td>\n",
       "      <td>7</td>\n",
       "      <td>21</td>\n",
       "      <td>310</td>\n",
       "      <td>1.0</td>\n",
       "      <td>bar</td>\n",
       "      <td>cooky cream</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10550</th>\n",
       "      <td>morrisons - frozen hash browns</td>\n",
       "      <td>frozen hash browns</td>\n",
       "      <td>morrisons</td>\n",
       "      <td>113</td>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>hash</td>\n",
       "      <td>frozen hash brown</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10551</th>\n",
       "      <td>toast - toast</td>\n",
       "      <td>toast</td>\n",
       "      <td>toast</td>\n",
       "      <td>250</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>slice</td>\n",
       "      <td>toast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10552</th>\n",
       "      <td>sainsburys - liquorice allsorts</td>\n",
       "      <td>liquorice allsorts</td>\n",
       "      <td>sainsburys</td>\n",
       "      <td>895</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>250.0</td>\n",
       "      <td>g</td>\n",
       "      <td>liquorice allsorts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10553</th>\n",
       "      <td>warburtons - fruity tea cakes</td>\n",
       "      <td>fruity tea cakes</td>\n",
       "      <td>warburtons</td>\n",
       "      <td>328</td>\n",
       "      <td>60</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>380</td>\n",
       "      <td>2.0</td>\n",
       "      <td>tea</td>\n",
       "      <td>fruity tea cake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10554</th>\n",
       "      <td>asda - malt wheaties</td>\n",
       "      <td>malt wheaties</td>\n",
       "      <td>asda</td>\n",
       "      <td>308</td>\n",
       "      <td>53</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>bowl</td>\n",
       "      <td>malt wheaties</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10310 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Name  \\\n",
       "0             my - mcdonalds espresso pronto  flat white   \n",
       "1      quest bar - banana nut muffin natural protein bar   \n",
       "2                     uncle tobys australia - vita brits   \n",
       "3                             pauls - smarter white milk   \n",
       "4                          quest bar - cookies and cream   \n",
       "...                                                  ...   \n",
       "10550                     morrisons - frozen hash browns   \n",
       "10551                                      toast - toast   \n",
       "10552                    sainsburys - liquorice allsorts   \n",
       "10553                      warburtons - fruity tea cakes   \n",
       "10554                               asda - malt wheaties   \n",
       "\n",
       "                                         Meal                   Brand  \\\n",
       "0       mcdonalds espresso pronto  flat white                     my    \n",
       "1       banana nut muffin natural protein bar              quest bar    \n",
       "2                                  vita brits  uncle tobys australia    \n",
       "3                          smarter white milk                  pauls    \n",
       "4                           cookies and cream              quest bar    \n",
       "...                                       ...                     ...   \n",
       "10550                      frozen hash browns              morrisons    \n",
       "10551                                   toast                  toast    \n",
       "10552                      liquorice allsorts             sainsburys    \n",
       "10553                        fruity tea cakes             warburtons    \n",
       "10554                           malt wheaties                   asda    \n",
       "\n",
       "       Calories  Carbs  Fat  Protein  Sodium  Amount     Units  \\\n",
       "0           412     29   24       21     258     2.0      tall   \n",
       "1           170     25    5       20     260    60.0         g   \n",
       "2           176     33    1        5     195     3.0  biscuits   \n",
       "3           342     34   12       24     402   600.0        ml   \n",
       "4           180     22    7       21     310     1.0       bar   \n",
       "...         ...    ...  ...      ...     ...     ...       ...   \n",
       "10550       113     16    5        1     100     1.0      hash   \n",
       "10551       250     53    0       18       0     2.5     slice   \n",
       "10552       895      0    4        0       0   250.0         g   \n",
       "10553       328     60    4       11     380     2.0       tea   \n",
       "10554       308     53    4       12       1     1.5      bowl   \n",
       "\n",
       "                                   processed  \n",
       "0       mcdonalds espresso pronto flat white  \n",
       "1      banana nut muffin natural protein bar  \n",
       "2                                  vita brit  \n",
       "3                         smarter white milk  \n",
       "4                                cooky cream  \n",
       "...                                      ...  \n",
       "10550                      frozen hash brown  \n",
       "10551                                  toast  \n",
       "10552                     liquorice allsorts  \n",
       "10553                        fruity tea cake  \n",
       "10554                          malt wheaties  \n",
       "\n",
       "[10310 rows x 11 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fruit salad', array([[1.]])),\n",
       " ('tropical fruit salad', array([[0.93929386]])),\n",
       " ('fresh fruit salad', array([[0.88147553]])),\n",
       " ('mixed berry fruit salad', array([[0.78877057]])),\n",
       " ('fruit chew', array([[0.76055011]])),\n",
       " ('fruit teacake', array([[0.75944644]])),\n",
       " ('kiwi fruit', array([[0.74754216]])),\n",
       " ('fruit gusher', array([[0.74638288]])),\n",
       " ('forest fruit', array([[0.73992296]])),\n",
       " ('cobb salad', array([[0.7209426]]))]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_similarities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract nutrition data for the chosen match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'fruit salad'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_similarities[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generic - fruit salad: 180kcal, protein: 4g, carbs: 42g, fats: 0g\n"
     ]
    }
   ],
   "source": [
    "df_meal = (df[df['processed'] == sorted_similarities[0][0]]).iloc[0]\n",
    "print(f\"{df_meal['Name']}: {df_meal['Calories']}kcal, protein: {df_meal['Protein']}g, carbs: {df_meal['Carbs']}g, fats: {df_meal['Fat']}g\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'generic - fruit salad'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meal['Name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can I get something that looks for an exact combination of words e.g. 'egg sandwich'?\n",
    "# if not found, look for nearest meaning i.e. egg with a carb (toast, muffin, roll, wrap etc.)?\n",
    "#  What about typos?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Find a list of words that don't exist in database, single foods is best\n",
    "# Split the current dataset in foods only and the rest\n",
    "# Add new foods to the dataset. Create embeddings\n",
    "# Separate the original list of foods and reconnect it with the rest of the dataframe\n",
    "# Add the tokenized column into the dataframe, so that to retrieve nutritional information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enriching the dataset with new words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload a list of new foods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the original foods and merge them back with the rest of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the newly trained model to embed the input"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
